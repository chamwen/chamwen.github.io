---
layout: post
title: 关于生成模型和判别模型
date: 2018-08-08 10:44
tags: [generative]
categories: Machine-Learning
description: "机器学习常用的两类模型，生成模型域判别模型的概念，定义和区别"
mathjax: true
---
* content
{:toc}
 机器学习常用的两类模型，生成模型域判别模型的概念，定义和区别。<!--more-->

**Cham's Blog 首发原创**



简单来说，对于判别模型，其不考虑 $x$ 与 $y$ 间的联合分布。对于诸如分类和回归问题，由于不考虑联合概率分布需要更多的样本和更多计算，采用判别模型可以取得更好的效果，总的来说判别式模型是估计一个模型参数 $\theta$，而生成式模型是来估计分布的参数。

### 判别模型

对于训练集上的$C$和$X$，判别模型的任务是对于新的测试集上的$\tilde{c}和\tilde{x}$，计算$\tilde{x}$属于某一类的概率，$P(\tilde{c}\mid \tilde{x})=P(\tilde{c}\mid \tilde{x},C,X)$，认为这个分布和参数$\theta$决定，而其核心又是最大化$P(\theta\mid C,X)$，来估计$\theta$，对于二分类 $y=0$与 $y=1$，只需要计算 $P(y\mid x)$ ，对于某一类若概率大于设定阈值，则为此类。
$$
\begin{align}
\arg\max P(\theta\mid X)&=\arg\max\frac{P(X\mid\theta)P(\theta)}{P(X)}=\arg\max(X\mid\theta)P(\theta)\\
&=\arg\max(\prod_{x_1}^{x_n}P(x_i\mid\theta))P(\theta)\\
&=\arg\max(\sum_{x_1}^{x_n}(logP(x_i\mid \theta)+logP(\theta)))\\
\end{align}
$$

**常见的判别式模型：**

- Logistic Regression（Logistical 回归，最大化似然函数）
- Linear discriminant analysis（线性判别分析） 
- Support vector machines（支持向量机） 
- Boosting（集成学习） 
- Conditional random fields（条件随机场） 
- Linear regression（线性回归） 
- Neural networks（神经网络） 




### 生成模型

学习$P(x\mid y)$的分布，其中 $x$ 为特征，$y$ 为类别，那么可以看作每一个类别特征的分布，然后同样利用极大似然估计得到每种类别的分布，预测的时候利用下面的公式得到结果： 
$$
\begin{align}
\arg\max_y{p(y\mid x)}&=\arg\max_y{\frac{p(x\mid y)p(y)}{p(x)}}\\
&=\arg\max_y{p(x\mid y)p(y)}
\end{align}
$$

其中生成模型关于 $p(x\mid y)$ 和 $p(y)$ 都有关于其分布的假设，比如 $p(x\mid y)$ 满足高斯分布或者指数分布，$p(y)$满足伯努利分布，然后利用EM算法求出分布的参数。对于二分类 $y=0$与 $y=1$，分别计算 $P(x\mid y)P(y)$ ，哪个值更大，则属于哪一类。



**常见的生成式模型:**

- Gaussian mixture model and other types of mixture model（高斯混合及其他类型混合模型） 
- Hidden Markov model（隐马尔可夫） 
- Naive Bayes（朴素贝叶斯，假设特征变量的各个维度是独立的，最小化后验概率） 
- AODE（平均单依赖估计） 
- Latent Dirichlet Allocation（LDA主题模型） 
- Restricted Boltzmann Machine（限制波兹曼机）
- 生成式模型是根据概率乘出结果，而判别式模型是给出输入，计算出结果。